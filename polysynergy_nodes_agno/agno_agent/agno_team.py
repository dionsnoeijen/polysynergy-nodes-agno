import asyncio
import inspect
import uuid
from textwrap import dedent
from typing import cast, Literal, Callable

from agno.agent import Agent
from agno.memory import AgentMemory
from agno.memory.v2 import Memory
from agno.models.base import Model
from agno.storage.base import Storage
from agno.team import Team

from polysynergy_node_runner.execution_context.send_flow_event import send_flow_event
from polysynergy_node_runner.setup_context.dock_property import dock_property, dock_select_values, dock_text_area, dock_dict
from polysynergy_node_runner.setup_context.node_decorator import node
from polysynergy_node_runner.setup_context.node_error import NodeError
from polysynergy_node_runner.setup_context.node_variable_settings import NodeVariableSettings
from polysynergy_node_runner.setup_context.path_settings import PathSettings
from polysynergy_node_runner.setup_context.service_node import ServiceNode

from polysynergy_nodes_agno.agno_agent.utils.extract_props_from_settings import extract_props_from_settings
from polysynergy_nodes_agno.agno_agent.utils.find_connected_members import find_connected_members
from polysynergy_nodes_agno.agno_agent.utils.find_connected_service import find_connected_service
from polysynergy_nodes_agno.agno_agent.utils.find_connected_memory_settings import find_connected_memory_settings
from polysynergy_nodes_agno.agno_agent.utils.find_connected_settings import find_connected_settings
from polysynergy_nodes_agno.agno_agent.utils.find_connected_storage_settings import find_connected_storage_settings
from polysynergy_nodes_agno.agno_agent.utils.find_connected_tools import find_connected_tools
from polysynergy_nodes_agno.agno_agent.utils.has_connected_agent_or_team import has_connected_agent_or_team
from polysynergy_nodes_agno.agno_agent.utils.find_connected_prompt import find_connected_prompt
from polysynergy_nodes_agno.agno_agent.utils.send_chat_stream_event import send_chat_stream_event


@node(
    name="Agno Team",
    category="agno_agent",
    icon="agno.svg",
)
class AgnoTeam(ServiceNode):

    avatar: str = NodeVariableSettings(
        label="Avatar",
        dock=dock_property(metadata={"custom": "openai_avatar"}),
        metadata={"custom": "openai_avatar"},
    )

    mode: str = NodeVariableSettings(
        dock=dock_select_values({
            "route": "Route",
            "coordinate": "Coordinate",
            "collaborate": "Collaborate",
        }),
        default="coordinate",
        info="The mode of operation for this team. Options are 'route', 'coordinate', or 'collaborate'.",
    )

    debug_mode: bool = NodeVariableSettings(
        group="debug",
        dock=True,
        node=False,
        info="Enable debug logs for this agent."
    )

    debug_level: str = NodeVariableSettings(
        group="debug",
        node=False,
        dock=dock_property(select_values={"1": "1", "2": "2"}),
        info="Debug verbosity level: 1 = basic, 2 = detailed."
    )

    monitoring: bool = NodeVariableSettings(
        dock=True,
        info="If True, logs agent events to agno.com for monitoring purposes.",
        node=False
    )

    telemetry: bool = NodeVariableSettings(
        dock=True,
        info="If True, enables minimal telemetry for usage analytics and diagnostics.",
        node=False
    )

    show_members_responses: bool = NodeVariableSettings(
        dock=True,
        default=True,
        node=False,
        info="If True, enables logging of member responses for debugging purposes.",
    )

    # INPUT

    model: Model | None = NodeVariableSettings(
        label="Model",
        has_in=True
    )

    memory: AgentMemory | None = NodeVariableSettings(
        label="Memory",
        has_in=True,
        info="Memory backend for the team (e.g., DynamoDB, SQLite)"
    )

    storage: Storage | None = NodeVariableSettings(
        label="Storage",
        has_in=True,
        info="Storage backend for conversation history (e.g., DynamoDB, SQLite)"
    )

    agent_or_team: Agent | Team | None = NodeVariableSettings(
        has_in=True,
        info="Specify whether this tool is for an agent or a team.",
    )

    prompt: str = NodeVariableSettings(
        label="Prompt",
        dock=True,
        has_in=True,
        info="The prompt or task description for the agent to execute."
    )

    team_name: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="The name of the team. If not set, it will be autogenerated.",
    )

    team_id: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="The ID of the team. If not set, it will be autogenerated.",
    )

    user_id: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="The ID of the user interacting with this team. If not set, it will be autogenerated.",
    )

    session_id: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="Unique session ID to group messages. Leave empty to auto-generate."
    )

    session_name: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="Optional name for the session, useful for debugging or display."
    )

    description: str | None = NodeVariableSettings(
        dock=True,
        has_in=True,
        info="A brief description of the team.",
    )

    instructions: str | None = NodeVariableSettings(
        dock=dock_text_area(rich=True),
        has_in=True,
        info="A list of instructions for the team. If not set, it will be autogenerated.",
    )

    expected_output: str | None = NodeVariableSettings(
        group="messaging",
        dock=dock_text_area(),
        has_in=True,
        info="The expected output from the team, included in the prompt."
    )

    success_criteria: str | None = NodeVariableSettings(
        group="messaging",
        dock=dock_text_area(),
        has_in=True,
        info="The criteria for success for the team, included in the prompt."
    )

    settings: dict = NodeVariableSettings(
        dock=dock_dict(
            enabled=False,
            key_label="Setting name",
            value_label="Setting value",
            in_switch=False,
            out_switch=False,
            type_field=False,
            in_switch_default=True,
            out_switch_default=False,
            info="Custom settings for the agent. Can include tool configurations or other parameters."
        ),
        info="Additional settings for the agent, such as tool configurations or custom parameters.",
        has_in=True,
        default=[
            {
                "handle": "context",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_context.TeamSettingsContext",
                "value": "polysynergy_nodes_agno.agent.team_settings_context.TeamSettingsContext",
            },
            {
                "handle": "history",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_history.TeamSettingsHistory",
                "value": "polysynergy_nodes_agno.agent.team_settings_history.TeamSettingsHistory",
            },
            {
                "handle": "knowledge",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_knowledge.TeamSettingsKnowledge",
                "value": "polysynergy_nodes_agno.agent.team_settings_knowledge.TeamSettingsKnowledge",
            },
            {
                "handle": "reasoning",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_reasoning.TeamSettingsReasoning",
                "value": "polysynergy_nodes_agno.agent.team_settings_reasoning.TeamSettingsReasoning",
            },
            {
                "handle": "session",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_session.TeamSettingsSession",
                "value": "polysynergy_nodes_agno.agent.team_settings_session.TeamSettingsSession",
            },
            {
                "handle": "storage",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_storage.TeamSettingsStorage",
                "value": "polysynergy_nodes_agno.agent.team_settings_storage.TeamSettingsStorage",
            },
            {
                "handle": "streaming",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_streaming.TeamSettingsStreaming",
                "value": "polysynergy_nodes_agno.agent.team_settings_streaming.TeamSettingsStreaming",
            },
            {
                "handle": "structured_output",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_structured_output.TeamSettingsStructuredOutput",
                "value": "polysynergy_nodes_agno.agent.team_settings_structured_output.TeamSettingsStructuredOutput",
            },
            {
                "handle": "system_message",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_system_message.TeamSettingsSystemMessage",
                "value": "polysynergy_nodes_agno.agent.team_settings_system_message.TeamSettingsSystemMessage",
            },
            {
                "handle": "team_history",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_team_history.TeamSettingsTeamHistory",
                "value": "polysynergy_nodes_agno.agent.team_settings_team_history.TeamSettingsTeamHistory",
            },
            {
                "handle": "team_tools",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_team_tools.TeamSettingsTeamTools",
                "value": "polysynergy_nodes_agno.agent.team_settings_team_tools.TeamSettingsTeamTools",
            },
            {
                "handle": "tools",
                "has_in": True,
                "has_out": False,
                "published": False,
                "type": "polysynergy_nodes_agno.agent.team_settings_tools.TeamSettingsTools",
                "value": "polysynergy_nodes_agno.agent.team_settings_tools.TeamSettingsTools",
            },
        ]
    )

    instance: Team = NodeVariableSettings(
        label="Instance",
        info="Instance of this node for use in the agent.",
        has_in=True,
        has_out=True,
        type="polysynergy_nodes_agno.agent.agno_team.AgnoTeam"
    )

    tools: bool = NodeVariableSettings(
        has_out=True,
        out_type_override="agno.team.team.Team",
        info="List of tools available to the model. Tools can be functions, Toolkits, or dict definitions.",
    )

    # METRICS

    metrics: dict = NodeVariableSettings(
        group="metrics",
        dock=False,
        has_out=True,
        info="Metrics collected during agent execution, such as response time or token usage."
    )

    # OUTPUT

    members: bool = NodeVariableSettings(
        out_type_override="agno.team.team.Team,agno.agent.agent.Agent",
        has_out=True,
    )

    true_path: bool | str = PathSettings("Answer", info="This is the path for successful execution.")
    false_path: bool | str | dict = PathSettings("Error", info="This is the path for errors during execution.")

    async def _setup(self):
        model = await find_connected_service(self, "model", Model)
        memory = await find_connected_service(self, "memory", Memory)
        storage = await find_connected_service(self, "storage", Storage)
        memory_settings = find_connected_memory_settings(self)
        storage_settings = find_connected_storage_settings(self, True)

        settings = await find_connected_settings(self)
        tool_info_list = await find_connected_tools(self)
        member_info_list = await find_connected_members(self)

        raw_level = self.debug_level or "1"  # default naar "1" als None of lege string
        debug_level = cast(Literal[1, 2], int(raw_level))

        raw_mode = self.mode or "coordinate"
        mode = cast(Literal["route", "coordinate", "collaborate"], raw_mode)
        if model is None:
            raise Exception("No model connected. Please connect a model to the node.")

        return model, memory, storage, memory_settings, storage_settings, settings, debug_level, mode, tool_info_list, member_info_list

    async def _create_team(self):
        (model,
         memory,
         storage,
         memory_settings,
         storage_settings,
         settings,
         debug_level,
         mode,
         tool_info_list,
         member_info_list
         ) = await self._setup()
        props = extract_props_from_settings(settings)

        props.update(storage_settings)

        self.team_id = self.team_id or str(uuid.uuid4())
        self.map_member_id_to_node_id = {}

        tool_instances = []
        member_instances = []
        function_name_to_node_id = {}

        for item in member_info_list or []:
            member = item['member']
            member_instances.append(member)
            node_id = item['node_id']
            member_id = getattr(member, "agent_id", None) or getattr(member, "team_id", None)
            if member_id and node_id:
               self.map_member_id_to_node_id[member_id] = node_id

        for item in tool_info_list:
            maybe_tool = item["tool"]
            toolkit = await maybe_tool if inspect.iscoroutine(maybe_tool) else maybe_tool
            tool_instances.append(toolkit)

            if hasattr(toolkit, "tools"):
                for tool in toolkit.tools:
                    fn_name = (
                        getattr(tool, "name", None)
                        or getattr(getattr(tool, "fn", None), "__name__", None)
                        or getattr(tool, "__name__", None)
                    )
                    if fn_name:
                        function_name_to_node_id[fn_name] = item["node_id"]


        async def tool_hook(function_name: str, function_call: Callable, arguments: dict):
            node_id = (
                function_name_to_node_id.get(function_name) or
                function_name
            )

            async def wrapper():
                send_flow_event(
                    flow_id=self.context.node_setup_version_id,
                    run_id=self.context.run_id,
                    node_id=node_id,
                    event_type='start_tool_or_member',
                )
                try:
                    result = function_call(**arguments)
                    if asyncio.iscoroutine(result):
                        result = await result
                    return result
                finally:
                    send_flow_event(
                        flow_id=self.context.node_setup_version_id,
                        run_id=self.context.run_id,
                        node_id=node_id,
                        event_type='end_tool_or_member',
                    )

            return await wrapper()

        print('TEAM PROPS', props)

        # Check for connected prompt node - prompt overrides manual settings
        prompt_data = find_connected_prompt(self)
        final_user_id = self.user_id
        final_session_id = self.session_id
        final_session_name = self.session_name
        
        if prompt_data:
            final_user_id = prompt_data['user_id']
            final_session_id = prompt_data['session_id'] 
            final_session_name = prompt_data['session_name']
            print(f'TEAM PROMPT OVERRIDE: user_id={final_user_id}, session_id={final_session_id}, session_name={final_session_name}')
        else:
            print(f'TEAM MANUAL SETTINGS: user_id={final_user_id}, session_id={final_session_id}, session_name={final_session_name}')

        self.instance = Team(
            name=self.team_name,
            members=member_instances or [],
            tools=tool_instances or [],
            mode=mode,
            model=model,
            memory=memory,
            storage=storage,
            team_id=self.team_id,
            user_id=final_user_id,
            session_id=final_session_id,
            session_name=final_session_name,
            instructions=dedent(self.instructions) if self.instructions else None,
            description=dedent(self.description) if self.description else None,
            expected_output=dedent(self.expected_output) if self.expected_output else None,
            success_criteria=dedent(self.success_criteria) if self.success_criteria else None,
            debug_mode=self.debug_mode,
            debug_level=debug_level,
            monitoring=self.monitoring,
            telemetry=self.telemetry,
            show_members_responses=self.show_members_responses,
            tool_hooks=[tool_hook],
            events_to_skip=[],
            **memory_settings,  # Spread memory settings from memory node
            **props
        )

    async def provide_instance(self):
        await self._create_team()
        return self.instance

    # ... unchanged setup above ...

    async def execute(self):
        if has_connected_agent_or_team(self):
            return

        await self._create_team()
        self.map_member_id_to_node_id[self.instance.team_id] = self.id

        try:
            stream = await self.instance.arun(self.prompt, stream=True)

            overall_parts: list[str] = []
            per_member_parts: dict[str | None, list[str]] = {}
            final_response_text: str | None = None

            async def _collect_response(generator):
                nonlocal final_response_text
                async for step in generator:
                    if step.event in ["RunResponseContent", "TeamRunResponseContent",
                                      "AgentRunResponseContent"]:
                        agent_id = getattr(step, "agent_id", None)
                        team_id = getattr(step, "team_id", None)
                        node_id = (self.map_member_id_to_node_id.get(agent_id)
                                   or self.map_member_id_to_node_id.get(team_id)
                                   or self.id)

                        chunk = getattr(step, "content", None)
                        if chunk:
                            overall_parts.append(chunk)
                            per_member_parts.setdefault(node_id, []).append(chunk)

                    # still stream events to UI
                    send_chat_stream_event(
                        flow_id=self.context.node_setup_version_id,
                        run_id=self.context.run_id,
                        node_id=(self.map_member_id_to_node_id.get(getattr(step, "agent_id", None))
                                 or self.map_member_id_to_node_id.get(getattr(step, "team_id", None))
                                 or self.id) if step.event in
                                                ["RunResponseContent", "TeamRunResponseContent",
                                                 "TeamToolCallCompleted", "AgentRunResponseContent",
                                                 "ToolCallCompleted"] else None,
                        event=step,
                    )

                    if step.event in ["TeamRunResponse", "RunResponse", "AgentRunResponse"]:
                        content = getattr(step, "content", None)
                        if content:
                            final_response_text = content

            await _collect_response(stream)

            # ⬇️ persist member responses NOW (after collection)
            storage = self.context.storage
            flow_id = self.context.node_setup_version_id
            run_id = self.context.run_id

            for node_id, parts in per_member_parts.items():
                if not node_id or node_id == self.id:
                    continue
                final_text = "".join(parts)

                # If you have the order, use it; otherwise let the upsert finder resolve it
                try:
                    order = next(
                        x["order"] for x in self.context.execution_flow["nodes_order"]
                        if x["id"] == node_id
                    )
                except StopIteration:
                    order = None

                # uses your helper that updates the existing node record
                storage.set_node_true_path(
                    flow_id=flow_id,
                    run_id=run_id,
                    node_id=node_id,
                    true_text=final_text,
                    order=order,
                    stage=self.context.stage,
                    sub_stage=self.context.sub_stage,
                )

            if not final_response_text:
                final_response_text = "".join(overall_parts) if overall_parts else ""

            self.true_path = final_response_text
            self.metrics = getattr(self.instance, "run_response", None)
            if self.metrics:
                self.metrics = self.instance.run_response.metrics

        except Exception as e:
            self.false_path = NodeError.format(e, True)
            return
